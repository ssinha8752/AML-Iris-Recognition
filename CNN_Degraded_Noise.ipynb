{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "futn946gyLZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eade64f3-79ca-4245-ab7a-4a3c06555024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CNN-Plain-Iris Epoch 1/10: 100%|██████████| 50/50 [25:07<00:00, 30.14s/it]\n",
            "CNN-Plain-Iris Epoch 2/10: 100%|██████████| 50/50 [00:12<00:00,  4.06it/s]\n",
            "CNN-Plain-Iris Epoch 3/10: 100%|██████████| 50/50 [00:12<00:00,  4.09it/s]\n",
            "CNN-Plain-Iris Epoch 4/10: 100%|██████████| 50/50 [00:12<00:00,  4.11it/s]\n",
            "CNN-Plain-Iris Epoch 5/10: 100%|██████████| 50/50 [00:12<00:00,  4.09it/s]\n",
            "CNN-Plain-Iris Epoch 6/10: 100%|██████████| 50/50 [00:12<00:00,  4.15it/s]\n",
            "CNN-Plain-Iris Epoch 7/10: 100%|██████████| 50/50 [00:12<00:00,  4.13it/s]\n",
            "CNN-Plain-Iris Epoch 8/10: 100%|██████████| 50/50 [00:12<00:00,  4.15it/s]\n",
            "CNN-Plain-Iris Epoch 9/10: 100%|██████████| 50/50 [00:12<00:00,  4.13it/s]\n",
            "CNN-Plain-Iris Epoch 10/10: 100%|██████████| 50/50 [00:12<00:00,  4.12it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "CNN-3Layer Epoch 1/10: 100%|██████████| 50/50 [00:12<00:00,  4.06it/s]\n",
            "CNN-3Layer Epoch 2/10: 100%|██████████| 50/50 [00:12<00:00,  4.12it/s]\n",
            "CNN-3Layer Epoch 3/10: 100%|██████████| 50/50 [00:12<00:00,  4.13it/s]\n",
            "CNN-3Layer Epoch 4/10: 100%|██████████| 50/50 [00:12<00:00,  4.10it/s]\n",
            "CNN-3Layer Epoch 5/10: 100%|██████████| 50/50 [00:12<00:00,  4.15it/s]\n",
            "CNN-3Layer Epoch 6/10: 100%|██████████| 50/50 [00:11<00:00,  4.18it/s]\n",
            "CNN-3Layer Epoch 7/10: 100%|██████████| 50/50 [00:11<00:00,  4.19it/s]\n",
            "CNN-3Layer Epoch 8/10: 100%|██████████| 50/50 [00:12<00:00,  4.14it/s]\n",
            "CNN-3Layer Epoch 9/10: 100%|██████████| 50/50 [00:11<00:00,  4.17it/s]\n",
            "CNN-3Layer Epoch 10/10: 100%|██████████| 50/50 [00:12<00:00,  4.14it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "CNN-9Layer Epoch 1/10: 100%|██████████| 50/50 [00:12<00:00,  4.05it/s]\n",
            "CNN-9Layer Epoch 2/10: 100%|██████████| 50/50 [00:12<00:00,  4.09it/s]\n",
            "CNN-9Layer Epoch 3/10: 100%|██████████| 50/50 [00:12<00:00,  4.08it/s]\n",
            "CNN-9Layer Epoch 4/10: 100%|██████████| 50/50 [00:12<00:00,  4.10it/s]\n",
            "CNN-9Layer Epoch 5/10: 100%|██████████| 50/50 [00:12<00:00,  4.09it/s]\n",
            "CNN-9Layer Epoch 6/10: 100%|██████████| 50/50 [00:12<00:00,  4.04it/s]\n",
            "CNN-9Layer Epoch 7/10: 100%|██████████| 50/50 [00:12<00:00,  4.12it/s]\n",
            "CNN-9Layer Epoch 8/10: 100%|██████████| 50/50 [00:12<00:00,  4.04it/s]\n",
            "CNN-9Layer Epoch 9/10: 100%|██████████| 50/50 [00:12<00:00,  4.11it/s]\n",
            "CNN-9Layer Epoch 10/10: 100%|██████████| 50/50 [00:12<00:00,  4.09it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 213MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:02<00:00, 233MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 195MB/s]\n",
            "AlexNet Epoch 1/10: 100%|██████████| 50/50 [00:13<00:00,  3.78it/s]\n",
            "AlexNet Epoch 2/10: 100%|██████████| 50/50 [00:12<00:00,  4.11it/s]\n",
            "AlexNet Epoch 3/10: 100%|██████████| 50/50 [00:12<00:00,  4.09it/s]\n",
            "AlexNet Epoch 4/10: 100%|██████████| 50/50 [00:12<00:00,  4.12it/s]\n",
            "AlexNet Epoch 5/10: 100%|██████████| 50/50 [00:12<00:00,  4.06it/s]\n",
            "AlexNet Epoch 6/10: 100%|██████████| 50/50 [00:12<00:00,  4.10it/s]\n",
            "AlexNet Epoch 7/10: 100%|██████████| 50/50 [00:12<00:00,  4.12it/s]\n",
            "AlexNet Epoch 8/10: 100%|██████████| 50/50 [00:12<00:00,  4.12it/s]\n",
            "AlexNet Epoch 9/10: 100%|██████████| 50/50 [00:12<00:00,  4.05it/s]\n",
            "AlexNet Epoch 10/10: 100%|██████████| 50/50 [00:12<00:00,  3.96it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "VGG16 Epoch 1/10: 100%|██████████| 50/50 [00:12<00:00,  4.00it/s]\n",
            "VGG16 Epoch 2/10: 100%|██████████| 50/50 [00:12<00:00,  4.07it/s]\n",
            "VGG16 Epoch 3/10: 100%|██████████| 50/50 [00:12<00:00,  4.03it/s]\n",
            "VGG16 Epoch 4/10: 100%|██████████| 50/50 [00:12<00:00,  4.09it/s]\n",
            "VGG16 Epoch 5/10: 100%|██████████| 50/50 [00:12<00:00,  4.10it/s]\n",
            "VGG16 Epoch 6/10: 100%|██████████| 50/50 [00:12<00:00,  3.90it/s]\n",
            "VGG16 Epoch 7/10: 100%|██████████| 50/50 [00:12<00:00,  4.13it/s]\n",
            "VGG16 Epoch 8/10: 100%|██████████| 50/50 [00:12<00:00,  4.03it/s]\n",
            "VGG16 Epoch 9/10: 100%|██████████| 50/50 [00:12<00:00,  4.12it/s]\n",
            "VGG16 Epoch 10/10: 100%|██████████| 50/50 [00:12<00:00,  4.09it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "ResNet18 Epoch 1/10: 100%|██████████| 50/50 [00:12<00:00,  4.05it/s]\n",
            "ResNet18 Epoch 2/10: 100%|██████████| 50/50 [00:12<00:00,  4.06it/s]\n",
            "ResNet18 Epoch 3/10: 100%|██████████| 50/50 [00:12<00:00,  4.06it/s]\n",
            "ResNet18 Epoch 4/10: 100%|██████████| 50/50 [00:12<00:00,  4.09it/s]\n",
            "ResNet18 Epoch 5/10: 100%|██████████| 50/50 [00:12<00:00,  4.14it/s]\n",
            "ResNet18 Epoch 6/10: 100%|██████████| 50/50 [00:12<00:00,  4.07it/s]\n",
            "ResNet18 Epoch 7/10: 100%|██████████| 50/50 [00:12<00:00,  4.06it/s]\n",
            "ResNet18 Epoch 8/10: 100%|██████████| 50/50 [00:12<00:00,  4.08it/s]\n",
            "ResNet18 Epoch 9/10: 100%|██████████| 50/50 [00:12<00:00,  4.03it/s]\n",
            "ResNet18 Epoch 10/10: 100%|██████████| 50/50 [00:12<00:00,  4.05it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "ResNet18-Aug Epoch 1/10: 100%|██████████| 50/50 [00:12<00:00,  3.92it/s]\n",
            "ResNet18-Aug Epoch 2/10: 100%|██████████| 50/50 [00:12<00:00,  3.86it/s]\n",
            "ResNet18-Aug Epoch 3/10: 100%|██████████| 50/50 [00:12<00:00,  3.92it/s]\n",
            "ResNet18-Aug Epoch 4/10: 100%|██████████| 50/50 [00:12<00:00,  3.89it/s]\n",
            "ResNet18-Aug Epoch 5/10: 100%|██████████| 50/50 [00:12<00:00,  3.91it/s]\n",
            "ResNet18-Aug Epoch 6/10: 100%|██████████| 50/50 [00:13<00:00,  3.81it/s]\n",
            "ResNet18-Aug Epoch 7/10: 100%|██████████| 50/50 [00:12<00:00,  3.90it/s]\n",
            "ResNet18-Aug Epoch 8/10: 100%|██████████| 50/50 [00:12<00:00,  3.90it/s]\n",
            "ResNet18-Aug Epoch 9/10: 100%|██████████| 50/50 [00:13<00:00,  3.83it/s]\n",
            "ResNet18-Aug Epoch 10/10: 100%|██████████| 50/50 [00:12<00:00,  3.85it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Model  Accuracy (%)  Precision (%)  Recall (%)  F1 Score (%)\n",
            "0        ResNet18         65.75      65.795262   67.766497     63.045685\n",
            "1      CNN-3Layer         56.75      56.625982   57.281145     52.922989\n",
            "2           VGG16         52.00      52.275407   52.848639     48.148106\n",
            "3         AlexNet         40.25      36.158952   39.424704     34.105193\n",
            "4    ResNet18-Aug         16.50      13.471056   15.993266     12.401119\n",
            "5  CNN-Plain-Iris          9.00       6.494805    9.090909      6.005516\n",
            "6   XGBoost-style          7.75       7.451145    8.458961      6.955013\n",
            "7      CNN-9Layer          1.00       0.266272    1.282051      0.371000\n",
            "Pickle files saved:\n",
            "→ Models: /content/drive/MyDrive/AML-PROJECT/all_models.pkl\n",
            "→ Results: /content/drive/MyDrive/AML-PROJECT/final_results.pkl\n"
          ]
        }
      ],
      "source": [
        "# CNN Degarded\n",
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Imports\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load & Prepare Data\n",
        "df = pd.read_csv('/content/drive/MyDrive/AML-PROJECT/iris_degrade.csv')\n",
        "df['ID'] = df['Label'].str.extract(r'(\\d+)', expand=False)\n",
        "valid_ids = df['ID'].value_counts()[lambda x: x >= 10].head(100).index\n",
        "df = df[df['ID'].isin(valid_ids)]\n",
        "df = df[df['Label'].notna() & df['Path'].notna()]\n",
        "df['Path'] = df['Path'].apply(lambda x: x if isinstance(x, str) and os.path.exists(x) else None)\n",
        "df = df[df['Path'].notna()]\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['ID'], random_state=42)\n",
        "le = LabelEncoder()\n",
        "train_df['encoded_label'] = le.fit_transform(train_df['Label'])\n",
        "val_df['encoded_label'] = le.transform(val_df['Label'])\n",
        "\n",
        "#Dataset Class\n",
        "class IrisDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.df.loc[idx, 'Path']).convert('RGB')\n",
        "        if self.transform: img = self.transform(img)\n",
        "        label = self.df.loc[idx, 'encoded_label']\n",
        "        return img, label\n",
        "\n",
        "#Transforms & DataLoaders\n",
        "basic_tf = transforms.Compose([transforms.Resize((64, 64)), transforms.ToTensor()])\n",
        "aug_tf = transforms.Compose([\n",
        "    transforms.Resize((64, 64)), transforms.RandomHorizontalFlip(), transforms.ColorJitter(),\n",
        "    transforms.RandomRotation(15), transforms.ToTensor()\n",
        "])\n",
        "train_loader = DataLoader(IrisDataset(train_df, basic_tf), batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(IrisDataset(val_df, basic_tf), batch_size=32)\n",
        "\n",
        "#Custom CNNs\n",
        "class CNNPlain(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 5, padding=2), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * 32 * 32, 128), nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "    def forward(self, x): return self.model(x)\n",
        "\n",
        "class CNN3(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.fc = nn.Linear(128 * 8 * 8, num_classes)\n",
        "    def forward(self, x): return self.fc(self.conv(x).view(x.size(0), -1))\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, ch):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(ch, ch, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(ch, ch, 3, padding=1), nn.ReLU()\n",
        "        )\n",
        "    def forward(self, x): return x + self.block(x)\n",
        "\n",
        "class CNN9(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.start = nn.Sequential(nn.Conv2d(3, 64, 5, padding=2), nn.ReLU(), nn.MaxPool2d(2))\n",
        "        self.res = nn.Sequential(\n",
        "            ResidualBlock(64), ResidualBlock(64),\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n",
        "            ResidualBlock(128), ResidualBlock(128)\n",
        "        )\n",
        "        self.fc = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)), nn.Flatten(),\n",
        "                                nn.Linear(128, 1024), nn.ReLU(), nn.Linear(1024, num_classes))\n",
        "    def forward(self, x): return self.fc(self.res(self.start(x)))\n",
        "\n",
        "# Training Function\n",
        "def train_eval(model, train_loader=train_loader, val_loader=val_loader, name=\"Model\", epochs=10):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        model.train()\n",
        "        for imgs, labels in tqdm(train_loader, desc=f\"{name} Epoch {ep+1}/{epochs}\"):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = loss_fn(model(imgs), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    preds, truths = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            out = model(imgs)\n",
        "            preds.extend(torch.argmax(out, dim=1).cpu().numpy())\n",
        "            truths.extend(labels.numpy())\n",
        "\n",
        "    acc = accuracy_score(truths, preds) * 100\n",
        "    prec = precision_score(truths, preds, average='macro') * 100\n",
        "    rec = recall_score(truths, preds, average='macro') * 100\n",
        "    f1 = f1_score(truths, preds, average='macro') * 100\n",
        "    return acc, prec, rec, f1\n",
        "\n",
        "#  Run All 8 Models\n",
        "results = []\n",
        "\n",
        "# Custom models\n",
        "custom_models = [\n",
        "    (\"CNN-Plain-Iris\", CNNPlain(len(le.classes_))),\n",
        "    (\"CNN-3Layer\", CNN3(len(le.classes_))),\n",
        "    (\"CNN-9Layer\", CNN9(len(le.classes_)))\n",
        "]\n",
        "for name, model in custom_models:\n",
        "    acc, prec, rec, f1 = train_eval(model, name=name)\n",
        "    results.append([name, acc, prec, rec, f1])\n",
        "\n",
        "# Pretrained models\n",
        "pretrained_cfgs = [\n",
        "    (\"AlexNet\", models.alexnet(pretrained=True)),\n",
        "    (\"VGG16\", models.vgg16(pretrained=True)),\n",
        "    (\"ResNet18\", models.resnet18(pretrained=True)),\n",
        "    (\"ResNet18-Aug\", models.resnet18(pretrained=True))\n",
        "]\n",
        "for name, model in pretrained_cfgs:\n",
        "    for p in model.parameters(): p.requires_grad = False\n",
        "    if 'resnet' in name.lower():\n",
        "        model.fc = nn.Linear(model.fc.in_features, len(le.classes_))\n",
        "    else:\n",
        "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, len(le.classes_))\n",
        "    loader = DataLoader(IrisDataset(train_df, aug_tf if \"Aug\" in name else basic_tf), batch_size=32, shuffle=True)\n",
        "    acc, prec, rec, f1 = train_eval(model, train_loader=loader, name=name)\n",
        "    results.append([name, acc, prec, rec, f1])\n",
        "\n",
        "# XGBoost-style on ResNet features\n",
        "resnet = models.resnet18(pretrained=True)\n",
        "resnet.fc = nn.Identity()\n",
        "for p in resnet.parameters(): p.requires_grad = False\n",
        "fe_train, y_train = [], []\n",
        "for xb, yb in DataLoader(IrisDataset(train_df, basic_tf), batch_size=32):\n",
        "    with torch.no_grad(): fe_train.extend(resnet(xb).numpy()); y_train.extend(yb.numpy())\n",
        "fe_val, y_val = [], []\n",
        "for xb, yb in val_loader:\n",
        "    with torch.no_grad(): fe_val.extend(resnet(xb).numpy()); y_val.extend(yb.numpy())\n",
        "xgb = GradientBoostingClassifier().fit(fe_train, y_train)\n",
        "xgb_preds = xgb.predict(fe_val)\n",
        "acc = accuracy_score(y_val, xgb_preds) * 100\n",
        "prec = precision_score(y_val, xgb_preds, average='macro') * 100\n",
        "rec = recall_score(y_val, xgb_preds, average='macro') * 100\n",
        "f1 = f1_score(y_val, xgb_preds, average='macro') * 100\n",
        "results.append([\"XGBoost-style\", acc, prec, rec, f1])\n",
        "\n",
        "# Display Final Sorted Results\n",
        "df_results = pd.DataFrame(results, columns=[\"Model\", \"Accuracy (%)\", \"Precision (%)\", \"Recall (%)\", \"F1 Score (%)\"])\n",
        "df_results = df_results.sort_values(by=\"Accuracy (%)\", ascending=False).reset_index(drop=True)\n",
        "print(df_results)\n",
        "\n",
        "# Save models and results as Pickle in Google Drive\n",
        "import pickle\n",
        "\n",
        "# Save final results DataFrame\n",
        "results_path = '/content/drive/MyDrive/AML-PROJECT/final_results.pkl'\n",
        "with open(results_path, 'wb') as f:\n",
        "    pickle.dump(df_results, f)\n",
        "\n",
        "# Save all models in a dictionary\n",
        "saved_models = {}\n",
        "\n",
        "# Save state_dict of custom models\n",
        "for name, model in custom_models:\n",
        "    saved_models[name] = model.cpu().state_dict()\n",
        "\n",
        "# Save state_dict of pretrained models\n",
        "for name, model in pretrained_cfgs:\n",
        "    saved_models[name] = model.cpu().state_dict()\n",
        "\n",
        "# Save full XGBoost model directly\n",
        "saved_models['XGBoost-style'] = xgb\n",
        "\n",
        "# Save the combined model dictionary\n",
        "model_path = '/content/drive/MyDrive/AML-PROJECT/all_models.pkl'\n",
        "with open(model_path, 'wb') as f:\n",
        "    pickle.dump(saved_models, f)\n",
        "\n",
        "print(f\"Pickle files saved:\\n→ Models: {model_path}\\n→ Results: {results_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Noise\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Imports\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "#  Load CSV and construct image paths\n",
        "csv_path = '/content/drive/MyDrive/AML-PROJECT/623final_all.csv'\n",
        "image_dir = '/content/drive/MyDrive/AML-PROJECT/623final_all'\n",
        "df = pd.read_csv(csv_path)\n",
        "df['Path'] = df['image_path'].apply(lambda x: os.path.join(image_dir, x))\n",
        "df = df[df['label'].notna() & df['Path'].apply(os.path.exists)]\n",
        "label_counts = df['label'].value_counts()\n",
        "valid_labels = label_counts[label_counts >= 2].index\n",
        "df = df[df['label'].isin(valid_labels)]\n",
        "le = LabelEncoder()\n",
        "df['encoded_label'] = le.fit_transform(df['label'])\n",
        "\n",
        "# Train/Validation Split\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['encoded_label'], random_state=42)\n",
        "\n",
        "# Dataset Class\n",
        "class IrisDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.df.loc[idx, 'Path']).convert('RGB')\n",
        "        if self.transform: img = self.transform(img)\n",
        "        label = self.df.loc[idx, 'encoded_label']\n",
        "        return img, label\n",
        "\n",
        "# Transforms and Loaders\n",
        "basic_tf = transforms.Compose([transforms.Resize((64, 64)), transforms.ToTensor()])\n",
        "aug_tf = transforms.Compose([\n",
        "    transforms.Resize((64, 64)), transforms.RandomHorizontalFlip(), transforms.ColorJitter(),\n",
        "    transforms.RandomRotation(15), transforms.ToTensor()\n",
        "])\n",
        "train_loader = DataLoader(IrisDataset(train_df, basic_tf), batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(IrisDataset(val_df, basic_tf), batch_size=32)\n",
        "\n",
        "# Custom CNN Models\n",
        "class CNNPlain(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 5, padding=2), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * 32 * 32, 128), nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "    def forward(self, x): return self.model(x)\n",
        "\n",
        "class CNN3(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.fc = nn.Linear(128 * 8 * 8, num_classes)\n",
        "    def forward(self, x): return self.fc(self.conv(x).view(x.size(0), -1))\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, ch):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(ch, ch, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(ch, ch, 3, padding=1), nn.ReLU()\n",
        "        )\n",
        "    def forward(self, x): return x + self.block(x)\n",
        "\n",
        "class CNN9(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.start = nn.Sequential(nn.Conv2d(3, 64, 5, padding=2), nn.ReLU(), nn.MaxPool2d(2))\n",
        "        self.res = nn.Sequential(\n",
        "            ResidualBlock(64), ResidualBlock(64),\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n",
        "            ResidualBlock(128), ResidualBlock(128)\n",
        "        )\n",
        "        self.fc = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)), nn.Flatten(),\n",
        "                                nn.Linear(128, 1024), nn.ReLU(), nn.Linear(1024, num_classes))\n",
        "    def forward(self, x): return self.fc(self.res(self.start(x)))\n",
        "\n",
        "#  Train and Evaluate Function\n",
        "def train_eval(model, train_loader, val_loader, name=\"Model\", epochs=10):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        model.train()\n",
        "        for imgs, labels in tqdm(train_loader, desc=f\"{name} Epoch {ep+1}/{epochs}\"):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = loss_fn(model(imgs), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    preds, truths = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            out = model(imgs)\n",
        "            preds.extend(torch.argmax(out, dim=1).cpu().numpy())\n",
        "            truths.extend(labels.numpy())\n",
        "\n",
        "    acc = accuracy_score(truths, preds) * 100\n",
        "    prec = precision_score(truths, preds, average='macro') * 100\n",
        "    rec = recall_score(truths, preds, average='macro') * 100\n",
        "    f1 = f1_score(truths, preds, average='macro') * 100\n",
        "    return acc, prec, rec, f1\n",
        "\n",
        "# Run All Models\n",
        "results = []\n",
        "num_classes = len(le.classes_)\n",
        "\n",
        "# Custom models\n",
        "custom_models = [\n",
        "    (\"CNN-Plain-Iris\", CNNPlain(num_classes)),\n",
        "    (\"CNN-3Layer\", CNN3(num_classes)),\n",
        "    (\"CNN-9Layer\", CNN9(num_classes))\n",
        "]\n",
        "for name, model in custom_models:\n",
        "    acc, prec, rec, f1 = train_eval(model, train_loader, val_loader, name)\n",
        "    results.append([name, acc, prec, rec, f1])\n",
        "\n",
        "# Pretrained models\n",
        "pretrained_cfgs = [\n",
        "    (\"AlexNet\", models.alexnet(pretrained=True)),\n",
        "    (\"VGG16\", models.vgg16(pretrained=True)),\n",
        "    (\"ResNet18\", models.resnet18(pretrained=True)),\n",
        "    (\"ResNet18-Aug\", models.resnet18(pretrained=True))\n",
        "]\n",
        "for name, model in pretrained_cfgs:\n",
        "    for p in model.parameters(): p.requires_grad = False\n",
        "    if 'resnet' in name.lower():\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    else:\n",
        "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "    tf = aug_tf if \"Aug\" in name else basic_tf\n",
        "    loader = DataLoader(IrisDataset(train_df, tf), batch_size=32, shuffle=True)\n",
        "    acc, prec, rec, f1 = train_eval(model, loader, val_loader, name)\n",
        "    results.append([name, acc, prec, rec, f1])\n",
        "\n",
        "# XGBoost-style\n",
        "resnet = models.resnet18(pretrained=True)\n",
        "resnet.fc = nn.Identity()\n",
        "for p in resnet.parameters(): p.requires_grad = False\n",
        "fe_train, y_train = [], []\n",
        "for xb, yb in DataLoader(IrisDataset(train_df, basic_tf), batch_size=32):\n",
        "    with torch.no_grad(): fe_train.extend(resnet(xb).numpy()); y_train.extend(yb.numpy())\n",
        "fe_val, y_val = [], []\n",
        "for xb, yb in val_loader:\n",
        "    with torch.no_grad(): fe_val.extend(resnet(xb).numpy()); y_val.extend(yb.numpy())\n",
        "xgb = GradientBoostingClassifier().fit(fe_train, y_train)\n",
        "xgb_preds = xgb.predict(fe_val)\n",
        "acc = accuracy_score(y_val, xgb_preds) * 100\n",
        "prec = precision_score(y_val, xgb_preds, average='macro') * 100\n",
        "rec = recall_score(y_val, xgb_preds, average='macro') * 100\n",
        "f1 = f1_score(y_val, xgb_preds, average='macro') * 100\n",
        "results.append([\"XGBoost-style\", acc, prec, rec, f1])\n",
        "\n",
        "# Final Results\n",
        "df_results = pd.DataFrame(results, columns=[\"Model\", \"Accuracy (%)\", \"Precision (%)\", \"Recall (%)\", \"F1 Score (%)\"])\n",
        "df_results = df_results.sort_values(by=\"Accuracy (%)\", ascending=False).reset_index(drop=True)\n",
        "print(df_results)\n",
        "\n",
        "# Save Pickle Files (Named for Noise Dataset)\n",
        "import pickle\n",
        "\n",
        "# Save results DataFrame\n",
        "results_path = '/content/drive/MyDrive/AML-PROJECT/noise_final_results.pkl'\n",
        "with open(results_path, 'wb') as f:\n",
        "    pickle.dump(df_results, f)\n",
        "\n",
        "# Save all models in a dictionary\n",
        "saved_models = {}\n",
        "\n",
        "# Save state_dict of custom models\n",
        "for name, model in custom_models:\n",
        "    saved_models[name] = model.cpu().state_dict()\n",
        "\n",
        "# Save state_dict of pretrained models\n",
        "for name, model in pretrained_cfgs:\n",
        "    saved_models[name] = model.cpu().state_dict()\n",
        "\n",
        "# Save full XGBoost model directly\n",
        "saved_models['XGBoost-style'] = xgb\n",
        "\n",
        "# Save the combined model dictionary\n",
        "model_path = '/content/drive/MyDrive/AML-PROJECT/noise_final_models.pkl'\n",
        "with open(model_path, 'wb') as f:\n",
        "    pickle.dump(saved_models, f)\n",
        "\n",
        "print(f\"\\n Pickle files saved for noise dataset:\\n→ Models: {model_path}\\n→ Results: {results_path}\")\n"
      ],
      "metadata": {
        "id": "4r4zA0iL_V6o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "601f505e-510a-4bf8-9a66-874cc5a94fd4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CNN-Plain-Iris Epoch 1/10: 100%|██████████| 50/50 [19:31<00:00, 23.43s/it]\n",
            "CNN-Plain-Iris Epoch 2/10: 100%|██████████| 50/50 [00:04<00:00, 11.68it/s]\n",
            "CNN-Plain-Iris Epoch 3/10: 100%|██████████| 50/50 [00:04<00:00, 12.30it/s]\n",
            "CNN-Plain-Iris Epoch 4/10: 100%|██████████| 50/50 [00:04<00:00, 11.85it/s]\n",
            "CNN-Plain-Iris Epoch 5/10: 100%|██████████| 50/50 [00:03<00:00, 12.50it/s]\n",
            "CNN-Plain-Iris Epoch 6/10: 100%|██████████| 50/50 [00:03<00:00, 12.54it/s]\n",
            "CNN-Plain-Iris Epoch 7/10: 100%|██████████| 50/50 [00:04<00:00, 11.77it/s]\n",
            "CNN-Plain-Iris Epoch 8/10: 100%|██████████| 50/50 [00:04<00:00, 11.99it/s]\n",
            "CNN-Plain-Iris Epoch 9/10: 100%|██████████| 50/50 [00:04<00:00, 12.50it/s]\n",
            "CNN-Plain-Iris Epoch 10/10: 100%|██████████| 50/50 [00:04<00:00, 11.88it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "CNN-3Layer Epoch 1/10: 100%|██████████| 50/50 [00:04<00:00, 11.17it/s]\n",
            "CNN-3Layer Epoch 2/10: 100%|██████████| 50/50 [00:04<00:00, 11.49it/s]\n",
            "CNN-3Layer Epoch 3/10: 100%|██████████| 50/50 [00:04<00:00, 12.35it/s]\n",
            "CNN-3Layer Epoch 4/10: 100%|██████████| 50/50 [00:04<00:00, 11.84it/s]\n",
            "CNN-3Layer Epoch 5/10: 100%|██████████| 50/50 [00:04<00:00, 12.34it/s]\n",
            "CNN-3Layer Epoch 6/10: 100%|██████████| 50/50 [00:04<00:00, 12.17it/s]\n",
            "CNN-3Layer Epoch 7/10: 100%|██████████| 50/50 [00:04<00:00, 11.87it/s]\n",
            "CNN-3Layer Epoch 8/10: 100%|██████████| 50/50 [00:04<00:00, 12.35it/s]\n",
            "CNN-3Layer Epoch 9/10: 100%|██████████| 50/50 [00:04<00:00, 12.12it/s]\n",
            "CNN-3Layer Epoch 10/10: 100%|██████████| 50/50 [00:04<00:00, 12.09it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "CNN-9Layer Epoch 1/10: 100%|██████████| 50/50 [00:04<00:00, 11.42it/s]\n",
            "CNN-9Layer Epoch 2/10: 100%|██████████| 50/50 [00:04<00:00, 11.73it/s]\n",
            "CNN-9Layer Epoch 3/10: 100%|██████████| 50/50 [00:04<00:00, 11.64it/s]\n",
            "CNN-9Layer Epoch 4/10: 100%|██████████| 50/50 [00:04<00:00, 11.25it/s]\n",
            "CNN-9Layer Epoch 5/10: 100%|██████████| 50/50 [00:04<00:00, 11.27it/s]\n",
            "CNN-9Layer Epoch 6/10: 100%|██████████| 50/50 [00:04<00:00, 12.01it/s]\n",
            "CNN-9Layer Epoch 7/10: 100%|██████████| 50/50 [00:04<00:00, 12.26it/s]\n",
            "CNN-9Layer Epoch 8/10: 100%|██████████| 50/50 [00:04<00:00, 11.14it/s]\n",
            "CNN-9Layer Epoch 9/10: 100%|██████████| 50/50 [00:04<00:00, 10.93it/s]\n",
            "CNN-9Layer Epoch 10/10: 100%|██████████| 50/50 [00:04<00:00, 11.43it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 228MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:02<00:00, 229MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 230MB/s]\n",
            "AlexNet Epoch 1/10: 100%|██████████| 50/50 [00:04<00:00, 10.06it/s]\n",
            "AlexNet Epoch 2/10: 100%|██████████| 50/50 [00:04<00:00, 11.28it/s]\n",
            "AlexNet Epoch 3/10: 100%|██████████| 50/50 [00:04<00:00, 11.80it/s]\n",
            "AlexNet Epoch 4/10: 100%|██████████| 50/50 [00:04<00:00, 12.23it/s]\n",
            "AlexNet Epoch 5/10: 100%|██████████| 50/50 [00:04<00:00, 12.01it/s]\n",
            "AlexNet Epoch 6/10: 100%|██████████| 50/50 [00:04<00:00, 11.81it/s]\n",
            "AlexNet Epoch 7/10: 100%|██████████| 50/50 [00:04<00:00, 11.82it/s]\n",
            "AlexNet Epoch 8/10: 100%|██████████| 50/50 [00:04<00:00, 11.89it/s]\n",
            "AlexNet Epoch 9/10: 100%|██████████| 50/50 [00:04<00:00, 12.32it/s]\n",
            "AlexNet Epoch 10/10: 100%|██████████| 50/50 [00:03<00:00, 12.64it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "VGG16 Epoch 1/10: 100%|██████████| 50/50 [00:04<00:00, 12.09it/s]\n",
            "VGG16 Epoch 2/10: 100%|██████████| 50/50 [00:04<00:00, 12.18it/s]\n",
            "VGG16 Epoch 3/10: 100%|██████████| 50/50 [00:04<00:00, 11.96it/s]\n",
            "VGG16 Epoch 4/10: 100%|██████████| 50/50 [00:04<00:00, 12.49it/s]\n",
            "VGG16 Epoch 5/10: 100%|██████████| 50/50 [00:04<00:00, 12.02it/s]\n",
            "VGG16 Epoch 6/10: 100%|██████████| 50/50 [00:04<00:00, 11.86it/s]\n",
            "VGG16 Epoch 7/10: 100%|██████████| 50/50 [00:04<00:00, 12.01it/s]\n",
            "VGG16 Epoch 8/10: 100%|██████████| 50/50 [00:04<00:00, 11.56it/s]\n",
            "VGG16 Epoch 9/10: 100%|██████████| 50/50 [00:04<00:00, 11.68it/s]\n",
            "VGG16 Epoch 10/10: 100%|██████████| 50/50 [00:03<00:00, 12.66it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "ResNet18 Epoch 1/10: 100%|██████████| 50/50 [00:04<00:00, 11.72it/s]\n",
            "ResNet18 Epoch 2/10: 100%|██████████| 50/50 [00:04<00:00, 11.26it/s]\n",
            "ResNet18 Epoch 3/10: 100%|██████████| 50/50 [00:04<00:00, 11.67it/s]\n",
            "ResNet18 Epoch 4/10: 100%|██████████| 50/50 [00:04<00:00, 11.65it/s]\n",
            "ResNet18 Epoch 5/10: 100%|██████████| 50/50 [00:04<00:00, 11.68it/s]\n",
            "ResNet18 Epoch 6/10: 100%|██████████| 50/50 [00:04<00:00, 12.04it/s]\n",
            "ResNet18 Epoch 7/10: 100%|██████████| 50/50 [00:04<00:00, 11.80it/s]\n",
            "ResNet18 Epoch 8/10: 100%|██████████| 50/50 [00:04<00:00, 11.86it/s]\n",
            "ResNet18 Epoch 9/10: 100%|██████████| 50/50 [00:04<00:00, 12.01it/s]\n",
            "ResNet18 Epoch 10/10: 100%|██████████| 50/50 [00:04<00:00, 11.57it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "ResNet18-Aug Epoch 1/10: 100%|██████████| 50/50 [00:04<00:00, 10.39it/s]\n",
            "ResNet18-Aug Epoch 2/10: 100%|██████████| 50/50 [00:04<00:00, 10.62it/s]\n",
            "ResNet18-Aug Epoch 3/10: 100%|██████████| 50/50 [00:04<00:00, 10.68it/s]\n",
            "ResNet18-Aug Epoch 4/10: 100%|██████████| 50/50 [00:04<00:00, 10.97it/s]\n",
            "ResNet18-Aug Epoch 5/10: 100%|██████████| 50/50 [00:04<00:00, 10.53it/s]\n",
            "ResNet18-Aug Epoch 6/10: 100%|██████████| 50/50 [00:04<00:00, 10.74it/s]\n",
            "ResNet18-Aug Epoch 7/10: 100%|██████████| 50/50 [00:04<00:00, 10.67it/s]\n",
            "ResNet18-Aug Epoch 8/10: 100%|██████████| 50/50 [00:04<00:00, 10.83it/s]\n",
            "ResNet18-Aug Epoch 9/10: 100%|██████████| 50/50 [00:04<00:00, 10.33it/s]\n",
            "ResNet18-Aug Epoch 10/10: 100%|██████████| 50/50 [00:04<00:00, 10.02it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Model  Accuracy (%)  Precision (%)  Recall (%)  F1 Score (%)\n",
            "0           VGG16         24.50      24.255357       24.50     22.198413\n",
            "1        ResNet18         21.00      20.159524       21.00     19.071032\n",
            "2         AlexNet         16.75      14.015807       16.75     13.586952\n",
            "3    ResNet18-Aug          9.50       6.172619        9.50      6.883333\n",
            "4  CNN-Plain-Iris          3.00       0.380579        3.00      0.591425\n",
            "5   XGBoost-style          1.25       1.475000        1.25      1.226190\n",
            "6      CNN-9Layer          0.50       0.002538        0.50      0.005051\n",
            "7      CNN-3Layer          0.50       0.002500        0.50      0.004975\n",
            "\n",
            " Pickle files saved for noise dataset:\n",
            "→ Models: /content/drive/MyDrive/AML-PROJECT/noise_final_models.pkl\n",
            "→ Results: /content/drive/MyDrive/AML-PROJECT/noise_final_results.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C7zv6NX_vmu_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}