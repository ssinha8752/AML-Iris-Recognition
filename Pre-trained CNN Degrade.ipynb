{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyND8mNdsLQ6ryP85P7W8F0A"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8IYxgWuNDbz2","executionInfo":{"status":"ok","timestamp":1751732385436,"user_tz":-480,"elapsed":1416,"user":{"displayName":"liu muzi","userId":"17190698434235273658"}},"outputId":"9ddb6ba1-d46f-4f1c-8346-ab11dbb60915"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# prompt: mount drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["### Pre-train CNN -Resnet18 on Degrade Dataset"],"metadata":{"id":"cb1TKhMvzr9d"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torchvision import models, transforms\n","from torch.utils.data import DataLoader, Dataset\n","from PIL import Image\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.svm import SVC\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","import torch.optim as optim\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","from datetime import datetime\n","import os"],"metadata":{"id":"ZFmTDvSiFDTi","executionInfo":{"status":"ok","timestamp":1751732396068,"user_tz":-480,"elapsed":10621,"user":{"displayName":"liu muzi","userId":"17190698434235273658"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 1. Load CSV\n","df = pd.read_csv('/content/drive/MyDrive/AML-PROJECT/iris_degrade.csv')\n","\n","# 2. Extract ID\n","df['ID'] = df['Label'].str.extract(r'(\\d+)', expand=False)\n","\n","# Count the number of occurrences of each ID (i.e. the number of samples per person)\n","id_counts = df['ID'].value_counts()\n","\n","# Select the IDs with occurrences ≥ 10, and take the first 100\n","valid_ids = id_counts[id_counts >= 10].head(100).index\n","\n","# Filter data for these IDs\n","df = df[df['ID'].isin(valid_ids)]\n","\n","# Optional: Save filtered train/val\n","train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['ID'], random_state=42)\n","\n","# 3. Encode labels\n","le = LabelEncoder()\n","train_df['encoded_label'] = le.fit_transform(train_df['Label'])\n","val_df['encoded_label'] = le.transform(val_df['Label'])\n","\n","# 4. Dataset class\n","class IrisDataset(Dataset):\n","    def __init__(self, df, transform=None):\n","        self.df = df\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.df.iloc[idx]['Path']\n","        label = self.df.iloc[idx]['encoded_label']\n","        image = Image.open(img_path).convert('RGB')\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label\n","\n","# 5.Define transformations and loaders\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406],\n","                         [0.229, 0.224, 0.225])\n","])\n","\n","train_dataset = IrisDataset(train_df, transform=transform)\n","val_dataset = IrisDataset(val_df, transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","\n","\n","# 6. Load ResNet18 and modify final layer\n","model = models.resnet18(pretrained=True)\n","num_classes = len(le.classes_)\n","model.fc = nn.Linear(model.fc.in_features, num_classes)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","\n","# 7.Loss function\n","# Define Focal Loss\n","class FocalLoss(nn.Module):\n","    def __init__(self, gamma=2.0):\n","        super(FocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.ce = nn.CrossEntropyLoss(reduction='none')\n","\n","    def forward(self, input, target):\n","        ce_loss = self.ce(input, target)\n","        pt = torch.exp(-ce_loss)\n","        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n","        return focal_loss.mean()\n","\n","# Define Label Smoothing Loss\n","class LabelSmoothingLoss(nn.Module):\n","    def __init__(self, classes, smoothing=0.1):\n","        super(LabelSmoothingLoss, self).__init__()\n","        self.confidence = 1.0 - smoothing\n","        self.smoothing = smoothing\n","        self.cls = classes\n","\n","    def forward(self, pred, target):\n","        pred = pred.log_softmax(dim=-1)\n","        with torch.no_grad():\n","            true_dist = torch.zeros_like(pred)\n","            true_dist.fill_(self.smoothing / (self.cls - 1))\n","            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n","        return torch.mean(torch.sum(-true_dist * pred, dim=-1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nj4-VL-UZcr3","executionInfo":{"status":"ok","timestamp":1751732398342,"user_tz":-480,"elapsed":2272,"user":{"displayName":"liu muzi","userId":"17190698434235273658"}},"outputId":"07cd07f4-05f4-4fe8-9bcb-2702531972df"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 177MB/s]\n"]}]},{"cell_type":"code","source":["# 8. Evaluation Function\n","def evaluate(model, loader, device):\n","    model.eval()\n","    y_true, y_pred = [], []\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x, y = x.to(device), y.to(device)\n","            outputs = model(x)\n","            preds = outputs.argmax(dim=1)\n","            y_true.extend(y.cpu().numpy())\n","            y_pred.extend(preds.cpu().numpy())\n","    return {\n","        'accuracy': accuracy_score(y_true, y_pred),\n","        'f1': f1_score(y_true, y_pred, average='weighted',zero_division=0),\n","        'precision': precision_score(y_true, y_pred, average='weighted',zero_division=0),\n","        'recall': recall_score(y_true, y_pred, average='weighted',zero_division=0)\n","    }\n","\n","#9. Training Function\n","def train_resnet18(loss_fn, optimizer_cls, epochs=5):\n","    model = models.resnet18(pretrained=True)\n","    model.fc = nn.Linear(model.fc.in_features, num_classes)\n","    model = model.to(device)\n","\n","    optimizer = optimizer_cls(model.parameters(), lr=1e-3)\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        total_loss = 0\n","        for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n","            x, y = x.to(device), y.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(x)\n","            loss = loss_fn(outputs, y)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","\n","        metrics = evaluate(model, val_loader, device)\n","        print(f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f} | \"\n","              f\"Acc: {metrics['accuracy']:.4f} | F1: {metrics['f1']:.4f}\")\n","\n","    final_metrics = evaluate(model, val_loader, device)\n","\n","\n","    timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n","    model_name = f\"resnet18__{loss_fn.__class__.__name__}__{optimizer_cls.__name__}__{timestamp}.pth\"\n","\n","    save_dir = \"/content/drive/MyDrive/AML-PROJECT/pretrained_cnn_Ly/Resnet18_Degrade\"\n","    os.makedirs(save_dir, exist_ok=True)\n","    model_path = os.path.join(save_dir, model_name)\n","\n","    torch.save(model.state_dict(), model_path)\n","    print(f\" Saved model to: {model_path}\")\n","\n","\n","    return {\n","        'loss_fn': loss_fn.__class__.__name__,\n","        'optimizer': optimizer_cls.__name__ if hasattr(optimizer_cls, '__name__') else str(optimizer_cls),\n","        'accuracy': final_metrics['accuracy'],\n","        'f1': final_metrics['f1'],\n","        'precision': final_metrics['precision'],\n","        'recall': final_metrics['recall'],\n","        'timestamp': datetime.now().isoformat()\n","    }"],"metadata":{"id":"u7462JSBFZoc","executionInfo":{"status":"ok","timestamp":1751732398389,"user_tz":-480,"elapsed":3,"user":{"displayName":"liu muzi","userId":"17190698434235273658"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#10. Run Experiments\n","loss_fns = [\n","    nn.CrossEntropyLoss(),\n","    LabelSmoothingLoss(classes=num_classes),\n","    FocalLoss(gamma=2)\n","]\n","\n","optimizers = [optim.Adam, optim.SGD]\n","\n","results = []\n","\n","for loss_fn in loss_fns:\n","    for opt in optimizers:\n","        try:\n","            print(f\"\\nRunning: {loss_fn.__class__.__name__} + {opt.__name__}\")\n","            result = train_resnet18(loss_fn, opt, epochs=5)\n","            results.append(result)\n","        except Exception as e:\n","            print(f\"[ERROR] Skipped: {loss_fn}, {opt} — {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xYI4Zy0lFojG","executionInfo":{"status":"ok","timestamp":1751733625383,"user_tz":-480,"elapsed":1226992,"user":{"displayName":"liu muzi","userId":"17190698434235273658"}},"outputId":"cefea945-e035-4939-c452-0a3416262807"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Running: CrossEntropyLoss + Adam\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/5: 100%|██████████| 50/50 [09:11<00:00, 11.03s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 | Loss: 4.7159 | Acc: 0.2325 | F1: 0.1949\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/5: 100%|██████████| 50/50 [00:15<00:00,  3.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 | Loss: 1.7428 | Acc: 0.7475 | F1: 0.7253\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5: 100%|██████████| 50/50 [00:15<00:00,  3.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 | Loss: 0.3406 | Acc: 0.9575 | F1: 0.9540\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/5: 100%|██████████| 50/50 [00:15<00:00,  3.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 | Loss: 0.0534 | Acc: 0.9900 | F1: 0.9882\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/5: 100%|██████████| 50/50 [00:15<00:00,  3.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 | Loss: 0.0139 | Acc: 0.9950 | F1: 0.9948\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":[" Saved model to: /content/drive/MyDrive/AML-PROJECT/pretrained_cnn_Ly/Resnet18_Degrade/resnet18__CrossEntropyLoss__Adam__20250705-163214.pth\n","\n","Running: CrossEntropyLoss + SGD\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/5: 100%|██████████| 50/50 [00:15<00:00,  3.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 | Loss: 5.4472 | Acc: 0.0025 | F1: 0.0010\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/5: 100%|██████████| 50/50 [00:15<00:00,  3.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 | Loss: 5.3449 | Acc: 0.0000 | F1: 0.0000\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5: 100%|██████████| 50/50 [00:15<00:00,  3.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 | Loss: 5.2451 | Acc: 0.0150 | F1: 0.0108\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/5: 100%|██████████| 50/50 [00:15<00:00,  3.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 | Loss: 5.1513 | Acc: 0.0075 | F1: 0.0058\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/5: 100%|██████████| 50/50 [00:15<00:00,  3.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 | Loss: 5.0623 | Acc: 0.0225 | F1: 0.0162\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":[" Saved model to: /content/drive/MyDrive/AML-PROJECT/pretrained_cnn_Ly/Resnet18_Degrade/resnet18__CrossEntropyLoss__SGD__20250705-163352.pth\n","\n","Running: LabelSmoothingLoss + Adam\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/5: 100%|██████████| 50/50 [00:15<00:00,  3.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 | Loss: 4.5854 | Acc: 0.3500 | F1: 0.2719\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/5: 100%|██████████| 50/50 [00:15<00:00,  3.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 | Loss: 2.0273 | Acc: 0.8300 | F1: 0.8157\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5: 100%|██████████| 50/50 [00:15<00:00,  3.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 | Loss: 1.1614 | Acc: 0.9475 | F1: 0.9429\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/5: 100%|██████████| 50/50 [00:15<00:00,  3.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 | Loss: 1.0284 | Acc: 0.9725 | F1: 0.9680\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/5: 100%|██████████| 50/50 [00:15<00:00,  3.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 | Loss: 0.9772 | Acc: 0.9725 | F1: 0.9709\n"," Saved model to: /content/drive/MyDrive/AML-PROJECT/pretrained_cnn_Ly/Resnet18_Degrade/resnet18__LabelSmoothingLoss__Adam__20250705-163531.pth\n","\n","Running: LabelSmoothingLoss + SGD\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Epoch 1/5: 100%|██████████| 50/50 [00:15<00:00,  3.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 | Loss: 5.4834 | Acc: 0.0000 | F1: 0.0000\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/5: 100%|██████████| 50/50 [00:15<00:00,  3.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 | Loss: 5.3895 | Acc: 0.0025 | F1: 0.0002\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5: 100%|██████████| 50/50 [00:15<00:00,  3.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 | Loss: 5.3116 | Acc: 0.0050 | F1: 0.0013\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/5: 100%|██████████| 50/50 [00:15<00:00,  3.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 | Loss: 5.2320 | Acc: 0.0100 | F1: 0.0019\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/5: 100%|██████████| 50/50 [00:15<00:00,  3.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 | Loss: 5.1661 | Acc: 0.0100 | F1: 0.0040\n"," Saved model to: /content/drive/MyDrive/AML-PROJECT/pretrained_cnn_Ly/Resnet18_Degrade/resnet18__LabelSmoothingLoss__SGD__20250705-163709.pth\n","\n","Running: FocalLoss + Adam\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Epoch 1/5: 100%|██████████| 50/50 [00:15<00:00,  3.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 | Loss: 4.6155 | Acc: 0.3350 | F1: 0.2692\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/5: 100%|██████████| 50/50 [00:15<00:00,  3.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 | Loss: 1.2349 | Acc: 0.8025 | F1: 0.7760\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5: 100%|██████████| 50/50 [00:15<00:00,  3.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 | Loss: 0.1600 | Acc: 0.9375 | F1: 0.9330\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/5: 100%|██████████| 50/50 [00:15<00:00,  3.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 | Loss: 0.0359 | Acc: 0.9625 | F1: 0.9570\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/5: 100%|██████████| 50/50 [00:15<00:00,  3.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 | Loss: 0.0250 | Acc: 0.9125 | F1: 0.9035\n"," Saved model to: /content/drive/MyDrive/AML-PROJECT/pretrained_cnn_Ly/Resnet18_Degrade/resnet18__FocalLoss__Adam__20250705-163847.pth\n","\n","Running: FocalLoss + SGD\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Epoch 1/5: 100%|██████████| 50/50 [00:15<00:00,  3.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 | Loss: 5.3939 | Acc: 0.0000 | F1: 0.0000\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/5: 100%|██████████| 50/50 [00:15<00:00,  3.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 | Loss: 5.2783 | Acc: 0.0000 | F1: 0.0000\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5: 100%|██████████| 50/50 [00:15<00:00,  3.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 | Loss: 5.1778 | Acc: 0.0025 | F1: 0.0013\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/5: 100%|██████████| 50/50 [00:15<00:00,  3.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 | Loss: 5.0735 | Acc: 0.0025 | F1: 0.0007\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/5: 100%|██████████| 50/50 [00:15<00:00,  3.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 | Loss: 4.9784 | Acc: 0.0175 | F1: 0.0131\n"," Saved model to: /content/drive/MyDrive/AML-PROJECT/pretrained_cnn_Ly/Resnet18_Degrade/resnet18__FocalLoss__SGD__20250705-164026.pth\n"]}]},{"cell_type":"code","source":["# 11. Summary Table\n","df_results = pd.DataFrame(results)\n","df_results = df_results.sort_values(by=\"accuracy\", ascending=False)\n","\n","print(\"\\n=== SUMMARY RESULTS ===\")\n","print(df_results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0cmMuFj_Ft0l","executionInfo":{"status":"ok","timestamp":1751733625535,"user_tz":-480,"elapsed":89,"user":{"displayName":"liu muzi","userId":"17190698434235273658"}},"outputId":"4ed5177d-179f-43bc-d491-4bc77e6a276f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== SUMMARY RESULTS ===\n","              loss_fn optimizer  accuracy        f1  precision  recall  \\\n","0    CrossEntropyLoss      Adam    0.9950  0.994762   0.996458  0.9950   \n","2  LabelSmoothingLoss      Adam    0.9725  0.970857   0.980542  0.9725   \n","4           FocalLoss      Adam    0.9125  0.903534   0.918492  0.9125   \n","1    CrossEntropyLoss       SGD    0.0225  0.016198   0.016089  0.0225   \n","5           FocalLoss       SGD    0.0175  0.013088   0.016722  0.0175   \n","3  LabelSmoothingLoss       SGD    0.0100  0.003964   0.002502  0.0100   \n","\n","                    timestamp  \n","0  2025-07-05T16:32:14.571924  \n","2  2025-07-05T16:35:31.108715  \n","4  2025-07-05T16:38:47.677001  \n","1  2025-07-05T16:33:52.877393  \n","5  2025-07-05T16:40:26.150366  \n","3  2025-07-05T16:37:09.179707  \n"]}]},{"cell_type":"markdown","source":["### Resnet18 on SVM  & logistic on degrade"],"metadata":{"id":"faLpa4gVz7e_"}},{"cell_type":"code","source":["# 1. Setup\n","import os\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","from tqdm import tqdm\n","from torchvision import models\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","import joblib\n","\n","# Setup device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Output directory to save models\n","OUTDIR = \"/content/drive/MyDrive/AML-PROJECT/pretrained_cnn_Ly/Resnet18_Degrade\"\n","os.makedirs(OUTDIR, exist_ok=True)\n","\n","# 2. Load Pretrained ResNet18\n","resnet = models.resnet18(pretrained=True)\n","resnet.fc = nn.Identity()  # Remove classification head\n","resnet = resnet.to(device)\n","resnet.eval()\n","\n","# 3. Feature Extraction\n","def extract_features(loader):\n","    features, labels = [], []\n","    with torch.no_grad():\n","        for imgs, lbls in tqdm(loader, desc=\"Extracting Features\"):\n","            imgs = imgs.to(device)\n","            feats = resnet(imgs)  # Output shape: [B, 512]\n","            features.append(feats.cpu().numpy())\n","            labels.append(lbls.numpy())\n","    return np.vstack(features), np.hstack(labels)\n","\n","# Extract features (assumes train_loader & val_loader already defined)\n","X_train, y_train = extract_features(train_loader)\n","X_val, y_val = extract_features(val_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PlRGcnEs03sK","executionInfo":{"status":"ok","timestamp":1751733643792,"user_tz":-480,"elapsed":18255,"user":{"displayName":"liu muzi","userId":"17190698434235273658"}},"outputId":"3a538f61-9439-4c96-fc3e-2d68977a1d07"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Extracting Features: 100%|██████████| 50/50 [00:14<00:00,  3.43it/s]\n","Extracting Features: 100%|██████████| 13/13 [00:03<00:00,  3.53it/s]\n"]}]},{"cell_type":"code","source":["# 4. Standardize Features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","\n","\n","# 5. Define Classifiers\n","models = {\n","    'Logistic_L2': LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000),\n","    'SVM_RBF': SVC(kernel='rbf', probability=True),\n","}\n","\n","# 6. Train, Save, Evaluate\n","results = []\n","\n","for name, clf in models.items():\n","    print(f\"\\n Training {name} ...\")\n","    clf.fit(X_train, y_train)\n","\n","    # Save trained model\n","    model_path = os.path.join(OUTDIR, f\"{name}.joblib\")\n","    joblib.dump(clf, model_path)\n","\n","    # Predict\n","    y_pred = clf.predict(X_val)\n","\n","    # Evaluate\n","    results.append({\n","        \"variant\": name,\n","        \"accuracy\": accuracy_score(y_val, y_pred),\n","        \"f1\": f1_score(y_val, y_pred, average=\"weighted\", zero_division=0),\n","        \"precision\": precision_score(y_val, y_pred, average=\"weighted\", zero_division=0),\n","        \"recall\": recall_score(y_val, y_pred, average=\"weighted\", zero_division=0)\n","    })\n","\n","# 7. Summary Table\n","print(\"\\n=== SUMMARY RESULTS (ResNet18 Features + ML Classifiers) ===\")\n","print(f\"{'variant':20s} {'accuracy':>8s} {'f1':>8s} {'precision':>10s} {'recall':>8s}\")\n","for r in results:\n","    print(f\"{r['variant']:20s} {r['accuracy']:8.4f} {r['f1']:8.4f} {r['precision']:10.4f} {r['recall']:8.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HuHOlzc1PoeO","executionInfo":{"status":"ok","timestamp":1751733656415,"user_tz":-480,"elapsed":12620,"user":{"displayName":"liu muzi","userId":"17190698434235273658"}},"outputId":"e31733a2-72a3-4480-96fc-09dfc978a03d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Training Logistic_L2 ...\n","\n"," Training SVM_RBF ...\n","\n","=== SUMMARY RESULTS (ResNet18 Features + ML Classifiers) ===\n","variant              accuracy       f1  precision   recall\n","Logistic_L2            0.9100   0.9051     0.9327   0.9100\n","SVM_RBF                0.8275   0.8223     0.8579   0.8275\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"--hGMsTdCmeQ","executionInfo":{"status":"ok","timestamp":1751733656423,"user_tz":-480,"elapsed":3,"user":{"displayName":"liu muzi","userId":"17190698434235273658"}}},"execution_count":9,"outputs":[]}]}